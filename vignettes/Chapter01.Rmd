---
title: "Chapter 1: From Bayes’ Rule to Bayes’ Theorem"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Chapter 1: From Bayes’ Rule to Bayes’ Theorem}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 8,
  fig.height = 6
)
knitr::opts_knit$set(global.par = TRUE)
pdfplots <- FALSE # default: FALSE; set this to TRUE only if you like pdf figures
```

```{r, include = FALSE}
par(mgp = c(1.6, .6, 0), mar = c(2.6, 2.6, 2.6, .4), lwd = 1)
```

# Section 1.3: Naive Bayes classifiers
## Example 1.3 and 1.4: Classifying categorical observations into two states

We have two firms, a reliable firm $A$ with $Pr(A) = 0.7$ and a less reliable
firm $A^C$ with $Pr(A^C) = 1 - 0.7 = 0.3$.

```{r}
PrA <- 0.7
PrAC <- 1 - PrA
```

The failure rate, i.e., the probability of a faulty item, is 0.01 for the
reliable firm $A$ and 0.05 for the less reliable firm $A^C$.

```{r}
PrFA <- 0.01
PrFAC <- 0.05
```

Assume that we observe any number of failures $y$ between 0 and 6 (from
$N = 100$ observations in total), but we don't know whether the items are from
company $A$ or $A^C$.

```{r}
N <- 100
y <- 0:6
```

We can now compute the probability of dealing with items from company $A$ by
using Bayes' theorem.

```{r}
theta1_y_unnormalized <- PrFA ^ y * (1 - PrFA) ^ (N - y) * PrA
theta0_y_unnormalized <- PrFAC ^ y * (1 - PrFAC) ^ (N - y) * PrAC
normalizer <- theta1_y_unnormalized + theta0_y_unnormalized

res <- rbind("reliable company" = theta1_y_unnormalized / normalizer,
             "less reliable company" = theta0_y_unnormalized / normalizer)
colnames(res) <- y
knitr::kable(round(res, 3))
```

Note that, of course, the probabilities of dealing with items from company $A$
and $A^C$ are complementary (i.e., sum to one).

Assuming we do not have any prior information about the probability of occurrence
of company $A$, we could simply set $Pr(A) = Pr(A^C) = 0.5$ and recompute the
posterior probabilities.

```{r}
PrA <- 0.5
PrAC <- 1 - PrA

theta1_y_unnormalized <- PrFA ^ y * (1 - PrFA) ^ (N - y) * PrA
theta0_y_unnormalized <- PrFAC ^ y * (1 - PrFAC) ^ (N - y) * PrAC
normalizer <- theta1_y_unnormalized + theta0_y_unnormalized

res <- rbind(theta1_y_unnormalized/ normalizer,
             theta0_y_unnormalized/ normalizer)
colnames(res) <- y
rownames(res) <- c("reliable company", "less reliable company")
knitr::kable(round(res, 3))
```


## Example 1.5: Classifying continuous observations into two states

We have a Bernoulli random variable $\vartheta$ with prior probability
$$Pr(\vartheta) = 0.55,$$
and we know for the females that
$$y|\vartheta_1 \sim Exp(\lambda),$$
and for the males that $$y|\vartheta_0 \sim G(\alpha, \beta),$$
where $\lambda = 1/2.2$, $\alpha = 5$, and $\beta = 5/5.5$.

```{r}
Prtheta = 0.55
lambda = 1/2.2
alpha = 5
beta = 5/5.5
```

We now plot the conditional densities for $y \in [0,10]$. Then, we compute the
non-normalized posteriors for $y \in \{1, 2, 3, 6, 8\}$, mark those in the plot,
and add lines to visualize the non-normalized posteriors.

```{r, echo=-2}
if (pdfplots) {
  pdf("1-3_1.pdf", width = 12, height = 8)
  par(mgp = c(1, .6, 0), mar = c(2, 1.5, 1.5, .1), lwd = 2)
}
y_all <- seq(0, 10, 0.2)
plot(y_all, dexp(y_all, lambda), type = "l", xlab = "Distance", ylab = "",
      main = "Conditional densities and non-normalized posteriors")
lines(y_all, dgamma(y_all, alpha, beta), col = "red")

y <- c(1, 2, 3, 6, 8)
theta1_y_unnormalized <- dexp(y, lambda) * Prtheta
theta0_y_unnormalized <- dgamma(y, alpha, beta) * (1 - Prtheta)

points(y, theta1_y_unnormalized)
points(y, theta0_y_unnormalized, col = "red", pch = 2)

theta1_y_all_unnormalized <- dexp(y_all, lambda) * Prtheta
theta0_y_all_unnormalized <- dgamma(y_all, alpha, beta) * (1 - Prtheta)

lines(y_all, theta1_y_all_unnormalized, lty = 2)
lines(y_all, theta0_y_all_unnormalized, lty = 2, col = "red")

legend("topright", c("Conditional density (female)",
                     "Conditional density (male)",
                     "Non-normalized posterior (female)",
                     "Non-normalized posterior (male)"),
       col = rep(c("black", "red"), 2), lty = rep(1:2, each = 2),
       pch = c(NA, NA, 1, 2))
```

Finally, here are the posterior probabilities. Note that each ratio of the pairs
of corresponding posterior probabilities is the same as each ratio of the
heights of the vertically corresponding points in the graph.

```{r, results = 'asis'}
normalizer <- theta1_y_unnormalized + theta0_y_unnormalized
theta1_y <- theta1_y_unnormalized / normalizer
theta0_y <- theta0_y_unnormalized / normalizer
res <- rbind(female = theta1_y, male = theta0_y)
colnames(res) <- y
knitr::kable(round(res, 3))
```

Visualized.

```{r, echo=-1}
if (pdfplots) {
  pdf("1-3_2.pdf", width = 12, height = 8)
  par(mgp = c(1.5, .6, 0), mar = c(2.5, 2.5, 1.5, .1), lwd = 2)
}
normalizer <- theta1_y_all_unnormalized + theta0_y_all_unnormalized
theta1_y_all <- theta1_y_all_unnormalized / normalizer
theta0_y_all <- theta0_y_all_unnormalized / normalizer
res <- rbind(female = theta1_y_all, male = theta0_y_all)
colnames(res) <- y_all
barplot(res, main = "Posterior probabilities", xlab = "Distance",
        ylab = "Probabilities", col = c("black", "red"))
```
