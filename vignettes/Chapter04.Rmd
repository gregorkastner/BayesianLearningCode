---
title: "Chapter 4: A First Bayesian Analysis of Continuous Data"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteEncoding{UTF-8}
  %\VignetteIndexEntry{Chapter 4: A First Bayesian Analysis of Continuous Data}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 8,
  fig.height = 6
)
knitr::opts_knit$set(global.par = TRUE)
pdfplots <- FALSE # default: FALSE; set this to TRUE only if you like pdf figures
```

```{r, include = FALSE}
par(mgp = c(1.6, .6, 0), mar = c(2.6, 2.6, 2.6, .4), lwd = 1)
```

# Swiss franc versus US dollar
## Example 4.1: The data

We use exchange rate data contained in  the package *stochvol*, covering the
period from January 3, 2000, until April 4, 2012. We are interested in the
percentage log returns of the the Swiss franc (CHF) against the US dollar (USD).

```{r, echo=-(1:2)}
if (pdfplots) {
  pdf("4-1_1.pdf", width = 8, height = 5)
  par(mar = c(2.4, 2.3, 1.5, .2), mgp = c(1.4, .5, 0))
}
par(mfrow = c(1, 2))
data(exrates, package = "stochvol")
y <- 100 * diff(log(exrates$USD / exrates$CHF))
hist(y, breaks = 50, main = "Histogram", xlab = "CHF/USD log returns")
ts.plot(y, main = "Time series plot", ylab = "CHF/USD log returns")
```

## Example 4.2: A first posterior

For a first joint inference on $\mu$ and $\sigma^2$, we assume a Gaussian
likelihood,
$$
p(\mathbf y|\mu,\sigma^2) = \prod_{i=1}^N p(y_i|\mu, \sigma^2)=
   \left(\frac{1}{2 \pi \sigma^2}\right)^{N/2}  \exp
\left( - \frac{1}{\sigma^2} \sum_{i=1}^{N} \frac{(y_i-\mu)^2}{2} \right).
$$

In addition, we assume the improper prior
$$
p(\mu, \sigma^2) \propto \frac{1}{\sigma^2},
$$
yielding the posterior
$$
p(\mu,\sigma^2|\mathbf y) =
f_N\left(\mu;\bar{y},\frac{\sigma^2}{N}\right)
f_{\mathcal{G}^{-1}}\left(\sigma^2;\frac{N-1}{2},\frac{N s_y^2}{2}\right).
$$
We can now plot this. Note that base R does not ship the density function of the
inverse gamma, so we define it ourselves using the transformation law of
densities. We also add the cumulative distribution function and the quantile
function, which we will need later.
Also note that in R, the Gaussian distribution is parameterized in terms
of mean and standard deviation (not mean and variance).

```{r, echo=-(1:2)}
if (pdfplots) {
  pdf("4-1_2.pdf", width = 8, height = 5)
  par(mar = c(1.2, 2, .9, 0))
} else par(mar = c(1.2, 1, .9, 0))
par(mfrow = c(2, 3))
dinvgamma <- function(x, a, b, log = FALSE) {
  logdens <- dgamma(1/x, a, b, log = TRUE) - 2 * log(x)
  if (log) logdens else exp(logdens)
}

pinvgamma <- function(q, a, b) {
  1 - pgamma(1 / q, a, b)
}

qinvgamma <- function(p, a, b) {
  1 / qgamma(1 - p, a, b)
}

posterior <- function(mu, sigma2, ybar, s2, N) {
  dnorm(mu, ybar, sqrt(sigma2 / N)) * dinvgamma(sigma2, (N - 1) / 2, N * s2 / 2)
}

mu <- seq(-.25, .25, length.out = 30)
sigma2 <- seq(.4, .7, length.out = 30)

# Generate the desired number of colors from a palette
nbcol <- 20
color <- topo.colors(nbcol)

mypar <- par(xpd = NA)
# Plot for different sample sizes
for (n in c(50, 100, 200, 500, 1000, length(y))) {
  ytmp <- head(y, n)
  z <- outer(mu, sigma2, posterior,
             ybar = mean(ytmp), s2 = var(ytmp) * (n - 1) / n, N = n)

  # Compute the z-values at the facet centers
  zfacet <- z[-1, -1] + z[-1, -ncol(z)] + z[-nrow(z), -1] + z[-nrow(z), -ncol(z)]

  # Recode facet z-values into color indices
  facetcol <- cut(zfacet, nbcol)

  # Perspective plot
  pmat <- persp(mu, sigma2, z, col = color[facetcol], ticktype = "detailed",
                main = paste0("N = ", n), nticks = 4, zlab = "", xlab = "",
                ylab = "", phi = 20, theta = -30, r = 100)
  
  # Add axis labels (done manually because persp() does not support expressions)
  loc <- trans3d(mean(mu) - .15 * diff(range(mu)),
                 min(sigma2) - .4 * diff(range(sigma2)),
                 0, pmat = pmat)
  text(loc$x, loc$y, expression(mu), cex = 1.3)
  
  loc <- trans3d(min(mu) - .35 * diff(range(mu)),
                 mean(sigma2) - .1 * diff(range(sigma2)),
                 0, pmat = pmat)
  text(loc$x, loc$y, expression(sigma^2), cex = 1.3)
}
par(xpd = FALSE)
```

## Example 4.3: Posterior marginals

We now want to visualize the univariate marginals of the bivariate posterior.
Note that R does not natively cater for the generalized Student's t distribution,
so we first define its (cumulative) density and quantile functions.

```{r, echo=-(1:2)}
if (pdfplots) {
  pdf("4-1_3.pdf", width = 10, height = 8)
  par(lwd = 2)
}
par(mfrow = c(2, 2), mgp = c(1.2, .4, 0), mar = c(2.1, 1.4, 1.5, .2))

dstudt <- function(x, location = 0, scale = 1, df, log = FALSE) {
  logdens <- dt((x - location)/scale, df = df, log = TRUE) - log(scale)
  if (log) logdens else exp(logdens)
}

pstudt <- function(x, location = 0, scale = 1, df) {
  pt((x - location) / scale, df = df)
}

qstudt <- function(p, location = 0, scale = 1, df) {
  location + scale * qt(p, df = df)
}

N <- length(y)
location <- mean(y)
scale <- sqrt(var(y) / N)
df <- N - 1
probs <- c(0.05, .5, .95)

mu <- seq(-.06, .06, length.out = 300)
plot(mu, dstudt(mu, location, scale, df), type = "l", xlab = expression(mu),
     ylab = "", main = "Posterior density and quantiles")
abline(h = 0, lty = 3)

qs <- qstudt(probs, location, scale, df)
ds <- dstudt(qs, location, scale, df)

for (i in seq_along(probs)) {
  lines(c(qs[i], qs[i]), c(0, ds[i]), lty = 2)
}
mtext(round(qs, 3), side = 1, line = -1, at = qs, cex = .5)

plot(mu, pstudt(mu, location, scale, df), type = "l", xlab = expression(mu),
     ylab = "", main = "Posterior cdf and quantiles")
abline(h = c(0, 1), lty = 3)

myxlim <- par("usr")[1] - .1 * diff(par("usr")[1:2])

for (i in seq_along(probs)) {
  lines(c(myxlim, qs[i]), c(probs[i], probs[i]), lty = 2)
  lines(c(qs[i], qs[i]), c(probs[i], 0), lty = 2)
}
mtext(round(qs, 3), side = 1, line = -1, at = qs, cex = .5)
mtext(probs, side = 2, at = probs, cex = .5)

cN <- (N - 1) / 2
CN <- var(y) * (N - 1) / 2

sigma2 <- seq(0.45, .6, length.out = 300)
plot(sigma2, dinvgamma(sigma2, cN, CN), type = "l", xlab = expression(sigma^2),
     ylab = "", main = "Posterior density and quantiles")
abline(h = 0, lty = 3)

qs <- qinvgamma(probs, cN, CN)
ds <- dinvgamma(qs, cN, CN)

for (i in seq_along(probs)) {
  lines(c(qs[i], qs[i]), c(0, ds[i]), lty = 2)
}
mtext(round(qs, 3), side = 1, line = -1, at = qs, cex = .5)

plot(sigma2, pinvgamma(sigma2, cN, CN), type = "l", xlab = expression(sigma^2),
     ylab = "", main = "Posterior cdf and quantiles")
abline(h = c(0, 1), lty = 3)

myxlim <- par("usr")[1] - .1 * diff(par("usr")[1:2])

for (i in seq_along(probs)) {
  lines(c(myxlim, qs[i]), c(probs[i], probs[i]), lty = 2)
  lines(c(qs[i], qs[i]), c(probs[i], 0), lty = 2)
}
mtext(round(qs, 3), side = 1, line = -1, at = qs, cex = .5)
mtext(probs, side = 2, at = probs, cex = .5)
```

## Example 4.4: Fitting a t distribution with known mean and known degrees of freedom

We first define a function for the unnormalized posterior density of $\sigma^2$.
Note that this function is not vectorized in its argument, $\sigma^2$. Rather,
it expects a scalar sigma2 and a data vector $\mathbf{y}$. Albeit not very fast,
we can vectorize this function using *Vectorize*.

```{r, echo=-(1:2)}
if (pdfplots) {
  pdf("4-2_1.pdf", width = 8, height = 5)
  par(mar = c(2.4, 1.4, 1.4, .2), mgp = c(1.5, .5, 0))
}
par(mfrow = c(1, 2))
nu <- 4

post_unnormalized_nonvec <- function(sigma2, y, nu, log = FALSE) {
  logdens <- -length(y) / 2 * log(sigma2) -
    (nu + 1) / 2 * sum(log(1 + y^2 / (nu * sigma2))) - log(sigma2)
  if (log) logdens else exp(logdens)
}
post_unnormalized <- Vectorize(post_unnormalized_nonvec, "sigma2")

sigma2 <- seq(0.1, 1, length.out = 3000)
pdf_u <- post_unnormalized(sigma2, y = y, nu = nu)

plot(sigma2, pdf_u, type = "l", xlab = expression(sigma^2),
     ylab = "", main = "Unnormalised posterior")
abline(h = 0, lty = 3)

cdf_u <- cumsum(pdf_u)
plot(sigma2, cdf_u, type = "l", xlab = expression(sigma^2),
     ylab = "", main = "Cumulative unnormalized posterior")
abline(h = c(0, cdf_u[length(cdf_u)]), lty = 3)
```

## Example 4.5: Bayesian learning of quantiles

For the Gaussian model, we simulate from $\mathcal{G}^{-1}(c_N, C_N)$ and then,
conditionally on these draws, from $\mathcal{N}(\bar{y}, \sigma^2 / N)$. Note,
again, that R's vectorization ability comes in handy. Here, in particular,
*rnorm*, can handle the so-called *varying parameter case*.

```{r}
set.seed(42)
alpha <- 0.05
ndraws <- 10000
sigma2draws <- 1 / rgamma(ndraws, cN, CN)
mudraws <- rnorm(ndraws, mean(y), sqrt(sigma2draws / N))
qnormdraws <- qnorm(alpha, mudraws, sqrt(sigma2draws))
```

For the $t_4$ model, we can use inverse transform sampling. First, we draw
uniformly from the interval spanned by 0 and the maximum of the nonnormalized
cumulative posterior. Then, for each draw, we find the interval of our pointwise
cdf approximation of the posterior, and interpolate linearly between the
interval boundaries.

```{r}
unifdraws <- runif(ndraws, 0, cdf_u[length(cdf_u)])
leftind <- findInterval(unifdraws, cdf_u)
rightind <- leftind + 1L
distprop <- (unifdraws - cdf_u[leftind]) / (cdf_u[rightind] - cdf_u[leftind])
sigma2draws <- sigma2[leftind] + distprop * (sigma2[rightind] - sigma2[leftind])
```

Let's do a quick graphical check whether the draws and our pdf align.

```{r}
myhist <- hist(sigma2draws, breaks = 100, xlab = expression(sigma^2),
               main = "Histogram of draws and nonnormalized pdf")
lines(sigma2, max(myhist$counts) / max(pdf_u) * pdf_u, col = 2)
```

Now, we can draw from the quantile distribution and plot these draws.

```{r, echo=-(1:2)}
if (pdfplots) {
  pdf("4-2_1.pdf", width = 8, height = 5)
  par(mar = c(2.4, 1.4, 1.4, .2), mgp = c(1.5, .5, 0))
}
par(mfrow = c(2, 1))
qtdraws <- sqrt(sigma2draws) * qt(alpha, df = nu)
minmax <- range(qnormdraws, qtdraws, quantile(y, alpha))
mybreaks <- seq(minmax[1] - .01 * diff(minmax),
                minmax[2] + .01 * diff(minmax),
                length.out = 100)
hist(qnormdraws, breaks = mybreaks)
points(quantile(y, alpha), 0, col = 2)
hist(qtdraws, breaks = mybreaks)
points(quantile(y, alpha), 0, col = 2)
```
